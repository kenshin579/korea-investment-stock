'''
í•œêµ­íˆ¬ìì¦ê¶Œ python wrapper
'''
import datetime
import json
import os
import pickle
import random
import threading
import time
import zipfile
from collections import deque, defaultdict
from concurrent.futures import ThreadPoolExecutor, as_completed
from functools import wraps
from pathlib import Path
from typing import Literal, Optional
from zoneinfo import ZoneInfo  # Requires Python 3.9+
import atexit

import pandas as pd
import requests

# Enhanced RateLimiter import
try:
    from .rate_limiting.enhanced_rate_limiter import EnhancedRateLimiter
    from .rate_limiting.enhanced_backoff_strategy import get_backoff_strategy
    from .rate_limiting.enhanced_retry_decorator import retry_on_rate_limit, retry_on_network_error
    from .error_handling.error_recovery_system import get_error_recovery_system
    from .monitoring.stats_manager import get_stats_manager
except ImportError:
    from rate_limiting.enhanced_rate_limiter import EnhancedRateLimiter
    from rate_limiting.enhanced_backoff_strategy import get_backoff_strategy
    from rate_limiting.enhanced_retry_decorator import retry_on_rate_limit, retry_on_network_error
    from error_handling.error_recovery_system import get_error_recovery_system
    from monitoring.stats_manager import get_stats_manager

EXCHANGE_CODE = {
    "í™ì½©": "HKS",
    "ë‰´ìš•": "NYS",
    "ë‚˜ìŠ¤ë‹¥": "NAS",
    "ì•„ë©•ìŠ¤": "AMS",
    "ë„ì¿„": "TSE",
    "ìƒí•´": "SHS",
    "ì‹¬ì²œ": "SZS",
    "ìƒí•´ì§€ìˆ˜": "SHI",
    "ì‹¬ì²œì§€ìˆ˜": "SZI",
    "í˜¸ì¹˜ë¯¼": "HSX",
    "í•˜ë…¸ì´": "HNX"
}

# í•´ì™¸ì£¼ì‹ ì£¼ë¬¸
# í•´ì™¸ì£¼ì‹ ì”ê³ 
EXCHANGE_CODE2 = {
    "ë¯¸êµ­ì „ì²´": "NASD",
    "ë‚˜ìŠ¤ë‹¥": "NAS",
    "ë‰´ìš•": "NYSE",
    "ì•„ë©•ìŠ¤": "AMEX",
    "í™ì½©": "SEHK",
    "ìƒí•´": "SHAA",
    "ì‹¬ì²œ": "SZAA",
    "ë„ì¿„": "TKSE",
    "í•˜ë…¸ì´": "HASE",
    "í˜¸ì¹˜ë¯¼": "VNSE"
}

EXCHANGE_CODE3 = {
    "ë‚˜ìŠ¤ë‹¥": "NASD",
    "ë‰´ìš•": "NYSE",
    "ì•„ë©•ìŠ¤": "AMEX",
    "í™ì½©": "SEHK",
    "ìƒí•´": "SHAA",
    "ì‹¬ì²œ": "SZAA",
    "ë„ì¿„": "TKSE",
    "í•˜ë…¸ì´": "HASE",
    "í˜¸ì¹˜ë¯¼": "VNSE"
}

EXCHANGE_CODE4 = {
    "ë‚˜ìŠ¤ë‹¥": "NAS",
    "ë‰´ìš•": "NYS",
    "ì•„ë©•ìŠ¤": "AMS",
    "í™ì½©": "HKS",
    "ìƒí•´": "SHS",
    "ì‹¬ì²œ": "SZS",
    "ë„ì¿„": "TSE",
    "í•˜ë…¸ì´": "HNX",
    "í˜¸ì¹˜ë¯¼": "HSX",
    "ìƒí•´ì§€ìˆ˜": "SHI",
    "ì‹¬ì²œì§€ìˆ˜": "SZI"
}

CURRENCY_CODE = {
    "ë‚˜ìŠ¤ë‹¥": "USD",
    "ë‰´ìš•": "USD",
    "ì•„ë©•ìŠ¤": "USD",
    "í™ì½©": "HKD",
    "ìƒí•´": "CNY",
    "ì‹¬ì²œ": "CNY",
    "ë„ì¿„": "JPY",
    "í•˜ë…¸ì´": "VND",
    "í˜¸ì¹˜ë¯¼": "VND"
}

MARKET_TYPE_MAP = {
    "KR": ["300"],  # "301", "302"
    "KRX": ["300"],  # "301", "302"
    "NASDAQ": ["512"],
    "NYSE": ["513"],
    "AMEX": ["529"],
    "US": ["512", "513", "529"],
    "TYO": ["515"],
    "JP": ["515"],
    "HKEX": ["501"],
    "HK": ["501", "543", "558"],
    "HNX": ["507"],
    "HSX": ["508"],
    "VN": ["507", "508"],
    "SSE": ["551"],
    "SZSE": ["552"],
    "CN": ["551", "552"]
}

MARKET_TYPE = Literal[
    "KRX",
    "NASDAQ",
    "NYSE",
    "AMEX",
    "TYO",
    "HKEX",
    "HNX",
    "HSX",
    "SSE",
    "SZSE",
]

EXCHANGE_TYPE = Literal[
    "NAS",
    "NYS",
    "AMS"
]

MARKET_CODE_MAP: dict[str, MARKET_TYPE] = {
    "300": "KRX",
    "301": "KRX",
    "302": "KRX",
    "512": "NASDAQ",
    "513": "NYSE",
    "529": "AMEX",
    "515": "TYO",
    "501": "HKEX",
    "543": "HKEX",
    "558": "HKEX",
    "507": "HNX",
    "508": "HSX",
    "551": "SSE",
    "552": "SZSE",
}

EXCHANGE_CODE_MAP: dict[str, EXCHANGE_TYPE] = {
    "NASDAQ": "NAS",
    "NYSE": "NYS",
    "AMEX": "AMS"
}

API_RETURN_CODE = {
    "SUCCESS": "0",  # ì¡°íšŒë˜ì—ˆìŠµë‹ˆë‹¤
    "EXPIRED_TOKEN": "1",  # ê¸°ê°„ì´ ë§Œë£Œëœ token ì…ë‹ˆë‹¤
    "NO_DATA": "7",  # ì¡°íšŒí•  ìë£Œê°€ ì—†ìŠµë‹ˆë‹¤
    "RATE_LIMIT_EXCEEDED": "EGW00201",  # Rate limit ì´ˆê³¼
}


# Note: retry_on_rate_limit decoratorëŠ” enhanced_retry_decorator ëª¨ë“ˆì—ì„œ importë¨


class KoreaInvestment:
    '''
    í•œêµ­íˆ¬ìì¦ê¶Œ REST API
    '''

    def __init__(self, api_key: str, api_secret: str, acc_no: str,
                 mock: bool = False):
        """ìƒì„±ì
        Args:
            api_key (str): ë°œê¸‰ë°›ì€ API key
            api_secret (str): ë°œê¸‰ë°›ì€ API secret
            acc_no (str): ê³„ì¢Œë²ˆí˜¸ ì²´ê³„ì˜ ì• 8ìë¦¬-ë’¤ 2ìë¦¬
            exchange (str): "ì„œìš¸", "ë‚˜ìŠ¤ë‹¥", "ë‰´ìš•", "ì•„ë©•ìŠ¤", "í™ì½©", "ìƒí•´", "ì‹¬ì²œ", # todo: exchangeëŠ” ì œê±° ì˜ˆì •
                            "ë„ì¿„", "í•˜ë…¸ì´", "í˜¸ì¹˜ë¯¼"
            mock (bool): True (mock trading), False (real trading)
        """
        self.mock = mock
        self.set_base_url(mock)
        self.api_key = api_key
        self.api_secret = api_secret

        # account number
        self.acc_no = acc_no
        self.acc_no_prefix = acc_no.split('-')[0]
        self.acc_no_postfix = acc_no.split('-')[1]
        
        # Enhanced RateLimiter ì„¤ì •
        self.rate_limiter = EnhancedRateLimiter(
            max_calls=15,  # ê¸°ë³¸ê°’ 20ì—ì„œ 15ë¡œ ê°ì†Œ
            per_seconds=1.0,
            safety_margin=0.8,  # ì‹¤ì œë¡œëŠ” 12íšŒ/ì´ˆ
            enable_min_interval=True,  # ìµœì†Œ ê°„ê²© ë³´ì¥
            enable_stats=True  # í†µê³„ ìˆ˜ì§‘ í™œì„±í™”
        )
        
        # ThreadPoolExecutor ê°œì„ 
        # ë™ì‹œ ì‹¤í–‰ ì œí•œì„ ìœ„í•œ ì„¸ë§ˆí¬ì–´ (ìµœëŒ€ 3ê°œë§Œ ë™ì‹œ ì‹¤í–‰)
        self.concurrent_limit = threading.Semaphore(3)
        # ì›Œì»¤ ìˆ˜ ê°ì†Œ (8 -> 3)
        self.executor = ThreadPoolExecutor(max_workers=3)
        # í”„ë¡œê·¸ë¨ ì¢…ë£Œ ì‹œ ìë™ ì •ë¦¬
        atexit.register(self.shutdown)

        # access token
        self.token_file = Path("~/.cache/mojito2/token.dat").expanduser()
        self.access_token = None
        if self.check_access_token():
            self.load_access_token()
        else:
            self.issue_access_token()

    def __enter__(self):
        """ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì§„ì…"""
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì¢…ë£Œ - ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        self.shutdown()
        return False  # ì˜ˆì™¸ë¥¼ ì „íŒŒ

    def __execute_concurrent_requests(self, method, stock_list, 
                                     batch_size: Optional[int] = None,
                                     batch_delay: float = 0.0,
                                     progress_interval: int = 10,
                                     dynamic_batch_controller=None):
        """ë³‘ë ¬ ìš”ì²­ ì‹¤í–‰ (ê°œì„ ëœ ë²„ì „ with ì—ëŸ¬ ì²˜ë¦¬ ê°•í™” ë° ë°°ì¹˜ ì²˜ë¦¬)
        
        Phase 3.4: ThreadPoolExecutor ì—ëŸ¬ ì²˜ë¦¬ í†µí•©
        Phase 4.1: ë°°ì¹˜ í¬ê¸° íŒŒë¼ë¯¸í„°í™”
        Phase 4.2: ë™ì  ë°°ì¹˜ ì¡°ì •
        
        Args:
            method: ì‹¤í–‰í•  ë©”ì„œë“œ
            stock_list: (symbol, market) íŠœí”Œ ë¦¬ìŠ¤íŠ¸
            batch_size: ë°°ì¹˜ í¬ê¸° (Noneì´ë©´ ì „ì²´ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬)
            batch_delay: ë°°ì¹˜ ê°„ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)
            progress_interval: ì§„í–‰ ìƒí™© ì¶œë ¥ ê°„ê²©
            dynamic_batch_controller: DynamicBatchController ì¸ìŠ¤í„´ìŠ¤ (ë™ì  ì¡°ì •ìš©)
        """
        from .rate_limiting.enhanced_retry_decorator import RateLimitError, APIError
        from .rate_limiting.enhanced_backoff_strategy import get_backoff_strategy
        
        futures = {}
        results = []
        
        # Rate Limit ì—ëŸ¬ ë°œìƒ ì‹œ ì „ì²´ ì‘ì—… ì¤‘ë‹¨ í”Œë˜ê·¸
        rate_limit_error_occurred = False
        rate_limit_error = None
        
        def wrapped_method(symbol, market):
            """ì„¸ë§ˆí¬ì–´ë¡œ ë™ì‹œ ì‹¤í–‰ ì œí•œ"""
            with self.concurrent_limit:
                return method(symbol, market)
        
        # ë°°ì¹˜ ì²˜ë¦¬ ì„¤ì •
        if dynamic_batch_controller:
            # ë™ì  ë°°ì¹˜ ì¡°ì • ì‚¬ìš©
            current_batch_size, current_batch_delay = dynamic_batch_controller.get_current_parameters()
            batch_size = current_batch_size
            batch_delay = current_batch_delay
            print(f"ğŸ¯ ë™ì  ë°°ì¹˜ ì¡°ì • ëª¨ë“œ: ì´ˆê¸° ë°°ì¹˜ í¬ê¸°={batch_size}, ëŒ€ê¸° ì‹œê°„={batch_delay:.1f}s")
        
        if batch_size is None:
            batches = [stock_list]  # ì „ì²´ë¥¼ í•˜ë‚˜ì˜ ë°°ì¹˜ë¡œ
        else:
            # stock_listë¥¼ batch_size í¬ê¸°ë¡œ ë‚˜ëˆ„ê¸°
            batches = [stock_list[i:i + batch_size] for i in range(0, len(stock_list), batch_size)]
            print(f"ğŸ“¦ ë°°ì¹˜ ì²˜ë¦¬ ëª¨ë“œ: {len(stock_list)}ê°œ í•­ëª©ì„ {len(batches)}ê°œ ë°°ì¹˜ë¡œ ì²˜ë¦¬ (ë°°ì¹˜ í¬ê¸°: {batch_size})")
        
        # ì „ì²´ ì‘ì—…ì„ ì¬ì‹œë„ ê°€ëŠ¥í•˜ë„ë¡ ê°ì‹¸ê¸°
        max_retries = 3  # ì „ì²´ ì‘ì—… ì¬ì‹œë„ íšŸìˆ˜
        retry_count = 0
        
        while retry_count < max_retries:
            futures.clear()
            results.clear()
            rate_limit_error_occurred = False
            rate_limit_error = None
            
            # ë°°ì¹˜ë³„ë¡œ ì²˜ë¦¬
            for batch_idx, batch in enumerate(batches):
                # ë™ì  ë°°ì¹˜ ì¡°ì •: ê° ë°°ì¹˜ë§ˆë‹¤ ìƒˆë¡œìš´ íŒŒë¼ë¯¸í„° ê°€ì ¸ì˜¤ê¸°
                if dynamic_batch_controller and batch_idx > 0:
                    new_batch_size, new_batch_delay = dynamic_batch_controller.get_current_parameters()
                    if new_batch_size != batch_size or new_batch_delay != batch_delay:
                        batch_size = new_batch_size
                        batch_delay = new_batch_delay
                        print(f"ğŸ“Š ë°°ì¹˜ íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸: í¬ê¸°={batch_size}, ëŒ€ê¸°={batch_delay:.1f}s")
                        # ìƒˆë¡œìš´ ë°°ì¹˜ í¬ê¸°ë¡œ ì¬êµ¬ì„±ì´ í•„ìš”í•œ ê²½ìš° (ë‹¤ìŒ ë£¨í”„ì—ì„œ ì ìš©)
                
                if len(batches) > 1:
                    print(f"\nğŸ”„ ë°°ì¹˜ {batch_idx + 1}/{len(batches)} ì²˜ë¦¬ ì¤‘... ({len(batch)}ê°œ í•­ëª©)")
                
                # ë°°ì¹˜ ì‹œì‘ ì‹œê°„ ê¸°ë¡
                batch_start_time = time.time()
                
                # ë°°ì¹˜ ë‚´ ìˆœì°¨ì  ì œì¶œë¡œ ì´ˆê¸° ë²„ìŠ¤íŠ¸ ë°©ì§€
                batch_futures = {}
                submit_delay = 0.01  # ê° ì œì¶œ ê°„ 10ms ëŒ€ê¸°
                
                # ë°°ì¹˜ í†µê³„ ì´ˆê¸°í™”
                batch_stats = {
                    'batch_idx': batch_idx,
                    'batch_size': len(batch),
                    'submit_start': time.time(),
                    'symbols': []
                }
                
                for idx, (symbol, market) in enumerate(batch):
                    # ìˆœì°¨ì  ì œì¶œë¡œ ì´ˆê¸° ë²„ìŠ¤íŠ¸ ë°©ì§€
                    if idx > 0 and submit_delay > 0:
                        time.sleep(submit_delay)
                    
                    future = self.executor.submit(wrapped_method, symbol, market)
                    batch_futures[future] = (symbol, market)
                    futures[future] = (symbol, market)
                    batch_stats['symbols'].append(symbol)
                
                batch_stats['submit_end'] = time.time()
                batch_stats['submit_duration'] = batch_stats['submit_end'] - batch_stats['submit_start']
                
                # ë°°ì¹˜ ë‚´ ì‘ì—… ì™„ë£Œ ëŒ€ê¸°
                batch_completed = 0
                batch_total = len(batch)
                batch_success_count = 0
                batch_error_count = 0
                
                try:
                    for future in as_completed(batch_futures, timeout=30):  # 30ì´ˆ íƒ€ì„ì•„ì›ƒ
                        symbol, market = batch_futures[future]
                        batch_completed += 1
                        
                        try:
                            result = future.result()
                            results.append(result)
                            batch_success_count += 1
                            
                            # ì§„í–‰ ìƒí™© ì¶œë ¥
                            if batch_completed % progress_interval == 0 or batch_completed == batch_total:
                                if len(batches) > 1:
                                    print(f"  ë°°ì¹˜ ì§„í–‰ë¥ : {batch_completed}/{batch_total} ({batch_completed/batch_total*100:.1f}%)")
                                else:
                                    total = len(stock_list)
                                    completed = len(results)
                                    print(f"ì²˜ë¦¬ ì§„í–‰ë¥ : {completed}/{total} ({completed/total*100:.1f}%)")
                                
                        except Exception as e:
                            error_info = {
                                'rt_cd': '9',  # ì—ëŸ¬ ì½”ë“œ
                                'msg1': f'Error: {str(e)}',
                                'error': True,
                                'symbol': symbol,
                                'market': market,
                                'error_type': type(e).__name__,
                                'error_details': str(e)
                            }
                            
                            # Rate Limit ì—ëŸ¬ ê°ì§€
                            if (isinstance(e, RateLimitError) or 
                                (hasattr(e, 'response') and isinstance(e.response, dict) and 
                                 e.response.get('rt_cd') == 'EGW00201') or
                                'EGW00201' in str(e)):
                                
                                print(f"âš ï¸ Rate Limit ì—ëŸ¬ ê°ì§€ - {symbol} ({market})")
                                rate_limit_error_occurred = True
                                rate_limit_error = e
                                
                                # ë‚¨ì€ ì‘ì—…ë“¤ ì·¨ì†Œ
                                for future in futures:
                                    if not future.done():
                                        future.cancel()
                                break
                            
                            # ì¼ë°˜ ì—ëŸ¬ ì²˜ë¦¬
                            print(f"âŒ ì—ëŸ¬ ë°œìƒ - {symbol} ({market}): {e}")
                            results.append(error_info)
                            batch_error_count += 1
                            
                            # Rate limit ì—ëŸ¬ì¸ ê²½ìš° ê¸°ë¡
                            if hasattr(self.rate_limiter, 'record_error'):
                                self.rate_limiter.record_error()
                    
                    # Rate Limit ì—ëŸ¬ê°€ ë°œìƒí•œ ê²½ìš° ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ë‹¨
                    if rate_limit_error_occurred:
                        break
                    
                    # ë™ì  ë°°ì¹˜ ì¡°ì •: ë°°ì¹˜ ê²°ê³¼ ê¸°ë¡
                    if dynamic_batch_controller:
                        batch_elapsed_time = time.time() - batch_start_time
                        dynamic_batch_controller.record_batch_result(
                            batch_size=len(batch),
                            success_count=batch_success_count,
                            error_count=batch_error_count,
                            elapsed_time=batch_elapsed_time
                        )
                    
                    # ë°°ì¹˜ë³„ ê²°ê³¼ í†µê³„ ìˆ˜ì§‘ ë° ë¡œê¹…
                    batch_elapsed_time = time.time() - batch_start_time
                    batch_stats['process_end'] = time.time()
                    batch_stats['total_duration'] = batch_elapsed_time
                    batch_stats['success_count'] = batch_success_count
                    batch_stats['error_count'] = batch_error_count
                    batch_stats['throughput'] = (batch_success_count + batch_error_count) / batch_elapsed_time if batch_elapsed_time > 0 else 0
                    
                    # ë°°ì¹˜ ì²˜ë¦¬ ê²°ê³¼ ë¡œê¹…
                    if len(batches) > 1:
                        print(f"\nğŸ“Š ë°°ì¹˜ {batch_idx + 1} í†µê³„:")
                        print(f"   - ì œì¶œ ì‹œê°„: {batch_stats['submit_duration']:.2f}ì´ˆ ({len(batch)}ê°œ)")
                        print(f"   - ì²˜ë¦¬ ì‹œê°„: {batch_elapsed_time:.2f}ì´ˆ")
                        print(f"   - ì„±ê³µ/ì‹¤íŒ¨: {batch_success_count}/{batch_error_count}")
                        print(f"   - ì²˜ë¦¬ëŸ‰: {batch_stats['throughput']:.1f} TPS")
                        
                        # ì—ëŸ¬ê°€ ìˆìœ¼ë©´ ì—ëŸ¬ íƒ€ì…ë³„ë¡œ ë¶„ì„
                        if batch_error_count > 0:
                            error_types = {}
                            for r in results[-len(batch):]:  # í˜„ì¬ ë°°ì¹˜ì˜ ê²°ê³¼ë§Œ
                                if r.get('error'):
                                    error_type = r.get('error_type', 'Unknown')
                                    error_types[error_type] = error_types.get(error_type, 0) + 1
                            print(f"   - ì—ëŸ¬ íƒ€ì…: {error_types}")
                    
                    # ë°°ì¹˜ ê°„ ëŒ€ê¸° (ë§ˆì§€ë§‰ ë°°ì¹˜ ì œì™¸)
                    if batch_delay > 0 and batch_idx < len(batches) - 1:
                        print(f"â±ï¸ ë‹¤ìŒ ë°°ì¹˜ê¹Œì§€ {batch_delay}ì´ˆ ëŒ€ê¸°...")
                        time.sleep(batch_delay)
                        
                except TimeoutError:
                    print(f"â±ï¸ íƒ€ì„ì•„ì›ƒ ë°œìƒ - 30ì´ˆ ë‚´ ì™„ë£Œë˜ì§€ ì•Šì€ ì‘ì—…ì´ ìˆìŠµë‹ˆë‹¤.")
                    # íƒ€ì„ì•„ì›ƒëœ ì‘ì—…ë“¤ ì²˜ë¦¬
                    for future, (symbol, market) in batch_futures.items():
                        if not future.done():
                            future.cancel()
                            results.append({
                                'rt_cd': '9',
                                'msg1': 'Timeout - operation took too long',
                                'error': True,
                                'symbol': symbol,
                                'market': market,
                                'error_type': 'TimeoutError'
                            })
                            batch_error_count += 1
                    # íƒ€ì„ì•„ì›ƒì´ ë°œìƒí•˜ë©´ ì „ì²´ ì²˜ë¦¬ ì¤‘ë‹¨
                    rate_limit_error_occurred = True
                    break
                
                # Rate Limit ì—ëŸ¬ê°€ ë°œìƒí•œ ê²½ìš° ë°°ì¹˜ ë£¨í”„ ì¢…ë£Œ
                if rate_limit_error_occurred:
                    break
            
            # Rate Limit ì—ëŸ¬ê°€ ë°œìƒí•œ ê²½ìš° ì¬ì‹œë„
            if rate_limit_error_occurred:
                retry_count += 1
                if retry_count < max_retries:
                    # Backoff ì „ëµ ì‚¬ìš©
                    backoff = get_backoff_strategy()
                    wait_time, reason = backoff.calculate_backoff(retry_count - 1)
                    
                    print(f"\nâ³ Rate Limit ì´ˆê³¼ë¡œ ì „ì²´ ì‘ì—… ì¬ì‹œë„ ì¤‘...")
                    print(f"   ëŒ€ê¸° ì‹œê°„: {wait_time:.2f}ì´ˆ ({reason})")
                    print(f"   ì¬ì‹œë„: {retry_count}/{max_retries}")
                    
                    time.sleep(wait_time)
                    continue  # ì „ì²´ ì‘ì—… ì¬ì‹œë„
                else:
                    # ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼
                    print(f"\nâŒ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼. ë¶€ë¶„ ê²°ê³¼ ë°˜í™˜.")
                    # ì‹¤íŒ¨í•œ ì‘ì—…ë“¤ë„ ì—ëŸ¬ ì •ë³´ë¡œ ì¶”ê°€
                    for future, (symbol, market) in futures.items():
                        if not future.done() or future.cancelled():
                            results.append({
                                'rt_cd': 'EGW00201',
                                'msg1': 'Rate limit exceeded - max retries reached',
                                'error': True,
                                'symbol': symbol,
                                'market': market,
                                'error_type': 'RateLimitError'
                            })
            
            # ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œ
            break
        
        # í†µê³„ ì¶œë ¥
        if hasattr(self.rate_limiter, 'print_stats'):
            self.rate_limiter.print_stats()
        
        # ì„±ê³µ/ì‹¤íŒ¨ ìš”ì•½
        success_count = sum(1 for r in results if not r.get('error', False))
        error_count = len(results) - success_count
        
        print(f"\nğŸ“Š ì²˜ë¦¬ ì™„ë£Œ - ì„±ê³µ: {success_count}, ì‹¤íŒ¨: {error_count}")
        if error_count > 0:
            error_types = {}
            for r in results:
                if r.get('error'):
                    error_type = r.get('error_type', 'Unknown')
                    error_types[error_type] = error_types.get(error_type, 0) + 1
            print(f"   ì—ëŸ¬ íƒ€ì…ë³„ ë¶„í¬: {error_types}")
        
        # ë°°ì¹˜ ì²˜ë¦¬ í†µê³„
        if len(batches) > 1:
            print(f"   ë°°ì¹˜ ìˆ˜: {len(batches)}, ë°°ì¹˜ í¬ê¸°: {batch_size}")
        
        # ë™ì  ë°°ì¹˜ ì¡°ì • í†µê³„
        if dynamic_batch_controller:
            controller_stats = dynamic_batch_controller.get_stats()
            print(f"\nğŸ¯ ë™ì  ë°°ì¹˜ ì¡°ì • í†µê³„:")
            print(f"   ìµœì¢… ë°°ì¹˜ í¬ê¸°: {controller_stats['current_batch_size']}")
            print(f"   ìµœì¢… ëŒ€ê¸° ì‹œê°„: {controller_stats['current_batch_delay']:.1f}s")
            print(f"   íŒŒë¼ë¯¸í„° ì¡°ì • íšŸìˆ˜: {controller_stats['adjustment_count']}")
            print(f"   ëª©í‘œ ì—ëŸ¬ìœ¨: {controller_stats['target_error_rate']:.1%}")
            print(f"   ì‹¤ì œ ì—ëŸ¬ìœ¨: {controller_stats['overall_error_rate']:.1%}")
        
        return results
    
    def __handle_rate_limit_error(self, retry_count: int):
        """Rate limit ì—ëŸ¬ ì²˜ë¦¬ (Exponential Backoff)
        
        DEPRECATED: Enhanced Backoff Strategyë¡œ ëŒ€ì²´ë¨
        ì´ ë©”ì„œë“œëŠ” í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€ë˜ë©°, í–¥í›„ ì œê±°ë  ì˜ˆì •ì…ë‹ˆë‹¤.
        
        Args:
            retry_count: ì¬ì‹œë„ íšŸìˆ˜ (0ë¶€í„° ì‹œì‘)
        """
        # Exponential backoff: 1, 2, 4, 8, 16, 32ì´ˆ
        wait_time = min(2 ** retry_count, 32)
        
        # Jitter ì¶”ê°€ (0~10% ëœë¤ ì¶”ê°€ ëŒ€ê¸°)
        jitter = random.uniform(0, 0.1 * wait_time)
        total_wait = wait_time + jitter
        
        print(f"Rate limit ì´ˆê³¼. {total_wait:.2f}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„... (ì‹œë„ {retry_count + 1}/5)")
        time.sleep(total_wait)

    def shutdown(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬ - ThreadPoolExecutor ì¢…ë£Œ"""
        if hasattr(self, 'executor') and self.executor:
            print("ThreadPoolExecutor ì¢…ë£Œ ì¤‘...")
            self.executor.shutdown(wait=True)
            self.executor = None
            print("ThreadPoolExecutor ì¢…ë£Œ ì™„ë£Œ")
        
        # Rate limiter í†µê³„ ìµœì¢… ì¶œë ¥ ë° ì €ì¥
        if hasattr(self, 'rate_limiter'):
            if hasattr(self.rate_limiter, 'get_stats'):
                stats = self.rate_limiter.get_stats()
                if stats.get('total_calls', 0) > 0:
                    print(f"\nìµœì¢… Rate Limiter í†µê³„:")
                    print(f"- ì´ í˜¸ì¶œ ìˆ˜: {stats['total_calls']}")
                    print(f"- ì—ëŸ¬ ìˆ˜: {stats['error_count']}")
                    print(f"- ì—ëŸ¬ìœ¨: {stats['error_rate']:.1%}")
            
            # í†µê³„ë¥¼ íŒŒì¼ë¡œ ì €ì¥
            if hasattr(self.rate_limiter, 'save_stats'):
                filepath = self.rate_limiter.save_stats(include_timestamp=True)
                if filepath:
                    print(f"- í†µê³„ ì €ì¥ë¨: {filepath}")
            
            # ìë™ ì €ì¥ ë¹„í™œì„±í™”
            if hasattr(self.rate_limiter, 'disable_auto_save'):
                self.rate_limiter.disable_auto_save()
        
        # Backoff ì „ëµ í†µê³„ ì¶œë ¥
        backoff_strategy = get_backoff_strategy()
        backoff_stats = backoff_strategy.get_stats()
        if backoff_stats['total_attempts'] > 0:
            print(f"\nìµœì¢… Backoff ì „ëµ í†µê³„:")
            print(f"- Circuit ìƒíƒœ: {backoff_stats['state']}")
            print(f"- ì´ ì‹œë„: {backoff_stats['total_attempts']}")
            print(f"- ì´ ì‹¤íŒ¨: {backoff_stats['total_failures']}")
            print(f"- ì„±ê³µë¥ : {backoff_stats['success_rate']:.1%}")
            print(f"- Circuit Open íšŸìˆ˜: {backoff_stats['circuit_opens']}")
            print(f"- í‰ê·  ë°±ì˜¤í”„ ì‹œê°„: {backoff_stats['avg_backoff_time']:.2f}ì´ˆ")
        
        # ì—ëŸ¬ ë³µêµ¬ ì‹œìŠ¤í…œ í†µê³„ ì¶œë ¥
        recovery_system = get_error_recovery_system()
        error_summary = recovery_system.get_error_summary(hours=24)
        if error_summary['total_errors'] > 0:
            print(f"\nìµœì¢… ì—ëŸ¬ ë³µêµ¬ í†µê³„ (ìµœê·¼ 24ì‹œê°„):")
            print(f"- ì´ ì—ëŸ¬ ìˆ˜: {error_summary['total_errors']}")
            print(f"- ì‹¬ê°ë„ë³„ ë¶„í¬: {error_summary['by_severity']}")
            print(f"- ë³µêµ¬ ì„±ê³µë¥ : {error_summary['recovery_rate']:.1%}")
            print(f"- ê°€ì¥ ë¹ˆë²ˆí•œ ì—ëŸ¬:")
            for error_info in error_summary['most_common'][:3]:
                print(f"  - {error_info['error']}: {error_info['count']}íšŒ")
        
        # ì—ëŸ¬ í†µê³„ íŒŒì¼ë¡œ ì €ì¥
        recovery_system.save_stats()
        
        # í†µí•© í†µê³„ ì €ì¥ (Phase 5.1)
        print("\ní†µí•© í†µê³„ ì €ì¥ ì¤‘...")
        stats_manager = get_stats_manager()
        
        # DynamicBatchControllerê°€ ìˆë‹¤ë©´ í¬í•¨
        batch_controller = None
        if hasattr(self, '_dynamic_batch_controller'):
            batch_controller = self._dynamic_batch_controller
        
        # ëª¨ë“  ëª¨ë“ˆì˜ í†µê³„ ìˆ˜ì§‘
        all_stats = stats_manager.collect_all_stats(
            rate_limiter=self.rate_limiter if hasattr(self, 'rate_limiter') else None,
            backoff_strategy=backoff_strategy,
            error_recovery=recovery_system,
            batch_controller=batch_controller
        )
        
        # JSON í˜•ì‹ìœ¼ë¡œ ì €ì¥
        json_path = stats_manager.save_stats(all_stats, format='json', include_timestamp=True)
        print(f"- í†µí•© í†µê³„ ì €ì¥ë¨ (JSON): {json_path}")
        
        # CSV í˜•ì‹ìœ¼ë¡œë„ ì €ì¥ (ìš”ì•½ ì •ë³´)
        csv_path = stats_manager.save_stats(all_stats, format='csv', include_timestamp=True)
        print(f"- í†µí•© í†µê³„ ì €ì¥ë¨ (CSV): {csv_path}")
        
        # ì••ì¶•ëœ JSON Lines í˜•ì‹ìœ¼ë¡œ ì €ì¥ (ì¥ê¸° ë³´ê´€ìš©)
        jsonl_gz_path = stats_manager.save_stats(
            all_stats, 
            format='jsonl', 
            compress=True,
            filename='stats_history',
            include_timestamp=False
        )
        print(f"- í†µê³„ ì´ë ¥ ì¶”ê°€ë¨ (JSONL.GZ): {jsonl_gz_path}")
        
        # ì‹œìŠ¤í…œ ìƒíƒœ ìš”ì•½ ì¶œë ¥
        summary = all_stats.get('summary', {})
        print(f"\nì‹œìŠ¤í…œ ìµœì¢… ìƒíƒœ: {summary.get('system_health', 'UNKNOWN')}")
        print(f"- ì „ì²´ API í˜¸ì¶œ: {summary.get('total_api_calls', 0):,}")
        print(f"- ì „ì²´ ì—ëŸ¬: {summary.get('total_errors', 0):,}")
        print(f"- ì „ì²´ ì—ëŸ¬ìœ¨: {summary.get('overall_error_rate', 0):.2%}")

    def set_base_url(self, mock: bool = True):
        """í…ŒìŠ¤íŠ¸(ëª¨ì˜íˆ¬ì) ì„œë²„ ì‚¬ìš© ì„¤ì •
        Args:
            mock(bool, optional): True: í…ŒìŠ¤íŠ¸ì„œë²„, False: ì‹¤ì„œë²„ Defaults to True.
        """
        if mock:
            self.base_url = "https://openapivts.koreainvestment.com:29443"
        else:
            self.base_url = "https://openapi.koreainvestment.com:9443"

    @retry_on_rate_limit(max_retries=3)  # í† í° ë°œê¸‰ì€ 3íšŒë§Œ ì¬ì‹œë„
    def issue_access_token(self):
        """OAuthì¸ì¦/ì ‘ê·¼í† í°ë°œê¸‰
        """
        path = "oauth2/tokenP"
        url = f"{self.base_url}/{path}"
        headers = {"content-type": "application/json"}
        data = {
            "grant_type": "client_credentials",
            "appkey": self.api_key,
            "appsecret": self.api_secret
        }

        resp = requests.post(url, headers=headers, json=data)
        resp_data = resp.json()
        self.access_token = f'Bearer {resp_data["access_token"]}'

        # 'expires_in' has no reference time and causes trouble:
        # The server thinks I'm expired but my token.dat looks still valid!
        # Hence, we use 'access_token_token_expired' here.
        # This error is quite big. I've seen 4000 seconds.
        timezone = ZoneInfo('Asia/Seoul')
        dt = datetime.datetime.strptime(resp_data['access_token_token_expired'], '%Y-%m-%d %H:%M:%S').replace(
            tzinfo=timezone)
        resp_data['timestamp'] = int(dt.timestamp())
        resp_data['api_key'] = self.api_key
        resp_data['api_secret'] = self.api_secret

        # dump access token
        self.token_file.parent.mkdir(parents=True, exist_ok=True)
        with self.token_file.open("wb") as f:
            pickle.dump(resp_data, f)

    def check_access_token(self) -> bool:
        """check access token

        Returns:
            Bool: True: token is valid, False: token is not valid
        """

        if not self.token_file.exists():
            return False

        with self.token_file.open("rb") as f:
            data = pickle.load(f)

        expire_epoch = data['timestamp']
        now_epoch = int(datetime.datetime.now().timestamp())
        status = False

        if (data['api_key'] != self.api_key) or (data['api_secret'] != self.api_secret):
            return False

        good_until = data['timestamp']
        ts_now = int(datetime.datetime.now().timestamp())
        return ts_now < good_until

    def load_access_token(self):
        """load access token
        """
        with self.token_file.open("rb") as f:
            data = pickle.load(f)
        self.access_token = f'Bearer {data["access_token"]}'

    def issue_hashkey(self, data: dict):
        """í•´ì‰¬í‚¤ ë°œê¸‰
        Args:
            data (dict): POST ìš”ì²­ ë°ì´í„°
        Returns:
            _type_: _description_
        """
        path = "uapi/hashkey"
        url = f"{self.base_url}/{path}"
        headers = {
            "content-type": "application/json",
            "appKey": self.api_key,
            "appSecret": self.api_secret,
            "User-Agent": "Mozilla/5.0"
        }
        resp = requests.post(url, headers=headers, data=json.dumps(data))
        haskkey = resp.json()["HASH"]
        return haskkey

    def fetch_search_stock_info_list(self, stock_market_list):
        return self.__execute_concurrent_requests(self.__fetch_search_stock_info, stock_market_list)

    def fetch_price_list(self, stock_list):
        return self.__execute_concurrent_requests(self.__fetch_price, stock_list)

    def fetch_price_list_with_batch(self, stock_list, batch_size=50, batch_delay=1.0, progress_interval=10):
        """ê°€ê²© ëª©ë¡ ì¡°íšŒ (ë°°ì¹˜ ì²˜ë¦¬ ì§€ì›)
        
        Args:
            stock_list: (symbol, market) íŠœí”Œ ë¦¬ìŠ¤íŠ¸
            batch_size: ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸ê°’: 50)
            batch_delay: ë°°ì¹˜ ê°„ ëŒ€ê¸° ì‹œê°„ (ì´ˆ, ê¸°ë³¸ê°’: 1.0)
            progress_interval: ì§„í–‰ ìƒí™© ì¶œë ¥ ê°„ê²© (ê¸°ë³¸ê°’: 10)
        
        Returns:
            list: ì¡°íšŒ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        return self.__execute_concurrent_requests(
            self.__fetch_price, 
            stock_list,
            batch_size=batch_size,
            batch_delay=batch_delay,
            progress_interval=progress_interval
        )
    
    def fetch_price_list_with_dynamic_batch(self, stock_list, dynamic_batch_controller=None):
        """ê°€ê²© ëª©ë¡ ì¡°íšŒ (ë™ì  ë°°ì¹˜ ì¡°ì •)
        
        Args:
            stock_list: (symbol, market) íŠœí”Œ ë¦¬ìŠ¤íŠ¸
            dynamic_batch_controller: DynamicBatchController ì¸ìŠ¤í„´ìŠ¤
                                     (Noneì´ë©´ ìë™ ìƒì„±)
        
        Returns:
            list: ì¡°íšŒ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        if dynamic_batch_controller is None:
            from .batch_processing.dynamic_batch_controller import DynamicBatchController
            dynamic_batch_controller = DynamicBatchController(
                initial_batch_size=50,
                initial_batch_delay=1.0,
                target_error_rate=0.01
            )
        
        return self.__execute_concurrent_requests(
            self.__fetch_price,
            stock_list,
            dynamic_batch_controller=dynamic_batch_controller
        )

    def __fetch_price(self, symbol: str, market: str = "KR") -> dict:
        """êµ­ë‚´ì£¼ì‹ì‹œì„¸/ì£¼ì‹í˜„ì¬ê°€ ì‹œì„¸
           í•´ì™¸ì£¼ì‹í˜„ì¬ê°€/í•´ì™¸ì£¼ì‹ í˜„ì¬ì²´ê²°ê°€

        Args:
            symbol (str): ì¢…ëª©ì½”ë“œ

        Returns:
            dict: _description_
        """

        if market == "KR" or market == "KRX":
            stock_info = self.__fetch_stock_info(symbol, market)
            symbol_type = self.__get_symbol_type(stock_info)
            if symbol_type == "ETF":
                resp_json = self.fetch_etf_domestic_price("J", symbol)
            else:
                resp_json = self.fetch_domestic_price("J", symbol)
        elif market == "US":
            resp_json = self.fetch_oversea_price(symbol)
        else:
            raise ValueError("Unsupported market type")

        return resp_json

    def __get_symbol_type(self, symbol_info):
        symbol_type = symbol_info['output']['prdt_clsf_name']
        if symbol_type == 'ì£¼ê¶Œ' or symbol_type == 'ìƒì¥REITS' or symbol_type == 'ì‚¬íšŒê°„ì ‘ìë³¸íˆ¬ìœµìíšŒì‚¬':
            return 'Stock'
        elif symbol_type == 'ETF':
            return 'ETF'

        return "Unknown"

    @retry_on_rate_limit()
    def fetch_etf_domestic_price(self, market_code: str, symbol: str) -> dict:
        """ì£¼ì‹í˜„ì¬ê°€ì‹œì„¸
        Args:
            market_code (str): ì‹œì¥ ë¶„ë¥˜ì½”ë“œ
            symbol (str): ì¢…ëª©ì½”ë“œ
        Returns:
            dict: API ê°œë°œ ê°€ì´ë“œ ì°¸ì¡°
        """
        path = "uapi/domestic-stock/v1/quotations/inquire-price"
        url = f"{self.base_url}/{path}"
        headers = {
            "content-type": "application/json",
            "authorization": self.access_token,
            "appKey": self.api_key,
            "appSecret": self.api_secret,
            "tr_id": "FHPST02400000"
        }
        params = {
            "fid_cond_mrkt_div_code": market_code,
            "fid_input_iscd": symbol
        }
        resp = requests.get(url, headers=headers, params=params)
        return resp.json()


    @retry_on_rate_limit()
    def fetch_domestic_price(self, market_code: str, symbol: str) -> dict:
        """ì£¼ì‹í˜„ì¬ê°€ì‹œì„¸
        Args:
            market_code (str): ì‹œì¥ ë¶„ë¥˜ì½”ë“œ
            symbol (str): ì¢…ëª©ì½”ë“œ
        Returns:
            dict: API ê°œë°œ ê°€ì´ë“œ ì°¸ì¡°
        """
        path = "uapi/domestic-stock/v1/quotations/inquire-price"
        url = f"{self.base_url}/{path}"
        headers = {
            "content-type": "application/json",
            "authorization": self.access_token,
            "appKey": self.api_key,
            "appSecret": self.api_secret,
            "tr_id": "FHKST01010100"
        }
        params = {
            "fid_cond_mrkt_div_code": market_code,
            "fid_input_iscd": symbol
        }
        resp = requests.get(url, headers=headers, params=params)
        return resp.json()

    def fetch_symbols(self):
        """fetch symbols from the exchange

        Returns:
            pd.DataFrame: pandas dataframe
        """
        if self.exchange == "ì„œìš¸":  # todo: exchangeëŠ” ì œê±° ì˜ˆì •
            df = self.fetch_kospi_symbols()
            kospi_df = df[['ë‹¨ì¶•ì½”ë“œ', 'í•œê¸€ëª…', 'ê·¸ë£¹ì½”ë“œ']].copy()
            kospi_df['ì‹œì¥'] = 'ì½”ìŠ¤í”¼'

            df = self.fetch_kosdaq_symbols()
            kosdaq_df = df[['ë‹¨ì¶•ì½”ë“œ', 'í•œê¸€ëª…', 'ê·¸ë£¹ì½”ë“œ']].copy()
            kosdaq_df['ì‹œì¥'] = 'ì½”ìŠ¤ë‹¥'

            df = pd.concat([kospi_df, kosdaq_df], axis=0)

        return df

    def download_master_file(self, base_dir: str, file_name: str, url: str):
        """download master file

        Args:
            base_dir (str): download directory
            file_name (str: filename
            url (str): url
        """
        os.chdir(base_dir)

        # delete legacy master file
        if os.path.exists(file_name):
            os.remove(file_name)

        # download master file
        resp = requests.get(url)
        with open(file_name, "wb") as f:
            f.write(resp.content)

        # unzip
        kospi_zip = zipfile.ZipFile(file_name)
        kospi_zip.extractall()
        kospi_zip.close()

    def parse_kospi_master(self, base_dir: str):
        """parse kospi master file

        Args:
            base_dir (str): directory where kospi code exists

        Returns:
            _type_: _description_
        """
        file_name = base_dir + "/kospi_code.mst"
        tmp_fil1 = base_dir + "/kospi_code_part1.tmp"
        tmp_fil2 = base_dir + "/kospi_code_part2.tmp"

        wf1 = open(tmp_fil1, mode="w", encoding="cp949")
        wf2 = open(tmp_fil2, mode="w")

        with open(file_name, mode="r", encoding="cp949") as f:
            for row in f:
                rf1 = row[0:len(row) - 228]
                rf1_1 = rf1[0:9].rstrip()
                rf1_2 = rf1[9:21].rstrip()
                rf1_3 = rf1[21:].strip()
                wf1.write(rf1_1 + ',' + rf1_2 + ',' + rf1_3 + '\n')
                rf2 = row[-228:]
                wf2.write(rf2)

        wf1.close()
        wf2.close()

        part1_columns = ['ë‹¨ì¶•ì½”ë“œ', 'í‘œì¤€ì½”ë“œ', 'í•œê¸€ëª…']
        df1 = pd.read_csv(tmp_fil1, header=None, encoding='cp949', names=part1_columns)

        field_specs = [
            2, 1, 4, 4, 4,
            1, 1, 1, 1, 1,
            1, 1, 1, 1, 1,
            1, 1, 1, 1, 1,
            1, 1, 1, 1, 1,
            1, 1, 1, 1, 1,
            1, 9, 5, 5, 1,
            1, 1, 2, 1, 1,
            1, 2, 2, 2, 3,
            1, 3, 12, 12, 8,
            15, 21, 2, 7, 1,
            1, 1, 1, 1, 9,
            9, 9, 5, 9, 8,
            9, 3, 1, 1, 1
        ]

        part2_columns = [
            'ê·¸ë£¹ì½”ë“œ', 'ì‹œê°€ì´ì•¡ê·œëª¨', 'ì§€ìˆ˜ì—…ì¢…ëŒ€ë¶„ë¥˜', 'ì§€ìˆ˜ì—…ì¢…ì¤‘ë¶„ë¥˜', 'ì§€ìˆ˜ì—…ì¢…ì†Œë¶„ë¥˜',
            'ì œì¡°ì—…', 'ì €ìœ ë™ì„±', 'ì§€ë°°êµ¬ì¡°ì§€ìˆ˜ì¢…ëª©', 'KOSPI200ì„¹í„°ì—…ì¢…', 'KOSPI100',
            'KOSPI50', 'KRX', 'ETP', 'ELWë°œí–‰', 'KRX100',
            'KRXìë™ì°¨', 'KRXë°˜ë„ì²´', 'KRXë°”ì´ì˜¤', 'KRXì€í–‰', 'SPAC',
            'KRXì—ë„ˆì§€í™”í•™', 'KRXì² ê°•', 'ë‹¨ê¸°ê³¼ì—´', 'KRXë¯¸ë””ì–´í†µì‹ ', 'KRXê±´ì„¤',
            'Non1', 'KRXì¦ê¶Œ', 'KRXì„ ë°•', 'KRXì„¹í„°_ë³´í—˜', 'KRXì„¹í„°_ìš´ì†¡',
            'SRI', 'ê¸°ì¤€ê°€', 'ë§¤ë§¤ìˆ˜ëŸ‰ë‹¨ìœ„', 'ì‹œê°„ì™¸ìˆ˜ëŸ‰ë‹¨ìœ„', 'ê±°ë˜ì •ì§€',
            'ì •ë¦¬ë§¤ë§¤', 'ê´€ë¦¬ì¢…ëª©', 'ì‹œì¥ê²½ê³ ', 'ê²½ê³ ì˜ˆê³ ', 'ë¶ˆì„±ì‹¤ê³µì‹œ',
            'ìš°íšŒìƒì¥', 'ë½êµ¬ë¶„', 'ì•¡ë©´ë³€ê²½', 'ì¦ìêµ¬ë¶„', 'ì¦ê±°ê¸ˆë¹„ìœ¨',
            'ì‹ ìš©ê°€ëŠ¥', 'ì‹ ìš©ê¸°ê°„', 'ì „ì¼ê±°ë˜ëŸ‰', 'ì•¡ë©´ê°€', 'ìƒì¥ì¼ì',
            'ìƒì¥ì£¼ìˆ˜', 'ìë³¸ê¸ˆ', 'ê²°ì‚°ì›”', 'ê³µëª¨ê°€', 'ìš°ì„ ì£¼',
            'ê³µë§¤ë„ê³¼ì—´', 'ì´ìƒê¸‰ë“±', 'KRX300', 'KOSPI', 'ë§¤ì¶œì•¡',
            'ì˜ì—…ì´ìµ', 'ê²½ìƒì´ìµ', 'ë‹¹ê¸°ìˆœì´ìµ', 'ROE', 'ê¸°ì¤€ë…„ì›”',
            'ì‹œê°€ì´ì•¡', 'ê·¸ë£¹ì‚¬ì½”ë“œ', 'íšŒì‚¬ì‹ ìš©í•œë„ì´ˆê³¼', 'ë‹´ë³´ëŒ€ì¶œê°€ëŠ¥', 'ëŒ€ì£¼ê°€ëŠ¥'
        ]

        df2 = pd.read_fwf(tmp_fil2, widths=field_specs, names=part2_columns)
        df = pd.merge(df1, df2, how='outer', left_index=True, right_index=True)

        # clean temporary file and dataframe
        del (df1)
        del (df2)
        os.remove(tmp_fil1)
        os.remove(tmp_fil2)
        return df

    def parse_kosdaq_master(self, base_dir: str):
        """parse kosdaq master file

        Args:
            base_dir (str): directory where kosdaq code exists

        Returns:
            _type_: _description_
        """
        file_name = base_dir + "/kosdaq_code.mst"
        tmp_fil1 = base_dir + "/kosdaq_code_part1.tmp"
        tmp_fil2 = base_dir + "/kosdaq_code_part2.tmp"

        wf1 = open(tmp_fil1, mode="w", encoding="cp949")
        wf2 = open(tmp_fil2, mode="w")
        with open(file_name, mode="r", encoding="cp949") as f:
            for row in f:
                rf1 = row[0:len(row) - 222]
                rf1_1 = rf1[0:9].rstrip()
                rf1_2 = rf1[9:21].rstrip()
                rf1_3 = rf1[21:].strip()
                wf1.write(rf1_1 + ',' + rf1_2 + ',' + rf1_3 + '\n')

                rf2 = row[-222:]
                wf2.write(rf2)

        wf1.close()
        wf2.close()

        part1_columns = ['ë‹¨ì¶•ì½”ë“œ', 'í‘œì¤€ì½”ë“œ', 'í•œê¸€ëª…']
        df1 = pd.read_csv(tmp_fil1, header=None, encoding="cp949", names=part1_columns)

        field_specs = [
            2, 1, 4, 4, 4,  # line 20
            1, 1, 1, 1, 1,  # line 27
            1, 1, 1, 1, 1,  # line 32
            1, 1, 1, 1, 1,  # line 38
            1, 1, 1, 1, 1,  # line 43
            1, 9, 5, 5, 1,  # line 48
            1, 1, 2, 1, 1,  # line 54
            1, 2, 2, 2, 3,  # line 64
            1, 3, 12, 12, 8,  # line 69
            15, 21, 2, 7, 1,  # line 75
            1, 1, 1, 9, 9,  # line 80
            9, 5, 9, 8, 9,  # line 85
            3, 1, 1, 1
        ]

        part2_columns = [
            'ê·¸ë£¹ì½”ë“œ', 'ì‹œê°€ì´ì•¡ê·œëª¨', 'ì§€ìˆ˜ì—…ì¢…ëŒ€ë¶„ë¥˜', 'ì§€ìˆ˜ì—…ì¢…ì¤‘ë¶„ë¥˜', 'ì§€ìˆ˜ì—…ì¢…ì†Œë¶„ë¥˜',  # line 20
            'ë²¤ì²˜ê¸°ì—…', 'ì €ìœ ë™ì„±', 'KRX', 'ETP', 'KRX100',  # line 27
            'KRXìë™ì°¨', 'KRXë°˜ë„ì²´', 'KRXë°”ì´ì˜¤', 'KRXì€í–‰', 'SPAC',  # line 32
            'KRXì—ë„ˆì§€í™”í•™', 'KRXì² ê°•', 'ë‹¨ê¸°ê³¼ì—´', 'KRXë¯¸ë””ì–´í†µì‹ ', 'KRXê±´ì„¤',  # line 38
            'íˆ¬ìì£¼ì˜', 'KRXì¦ê¶Œ', 'KRXì„ ë°•', 'KRXì„¹í„°_ë³´í—˜', 'KRXì„¹í„°_ìš´ì†¡',  # line 43
            'KOSDAQ150', 'ê¸°ì¤€ê°€', 'ë§¤ë§¤ìˆ˜ëŸ‰ë‹¨ìœ„', 'ì‹œê°„ì™¸ìˆ˜ëŸ‰ë‹¨ìœ„', 'ê±°ë˜ì •ì§€',  # line 48
            'ì •ë¦¬ë§¤ë§¤', 'ê´€ë¦¬ì¢…ëª©', 'ì‹œì¥ê²½ê³ ', 'ê²½ê³ ì˜ˆê³ ', 'ë¶ˆì„±ì‹¤ê³µì‹œ',  # line 54
            'ìš°íšŒìƒì¥', 'ë½êµ¬ë¶„', 'ì•¡ë©´ë³€ê²½', 'ì¦ìêµ¬ë¶„', 'ì¦ê±°ê¸ˆë¹„ìœ¨',  # line 64
            'ì‹ ìš©ê°€ëŠ¥', 'ì‹ ìš©ê¸°ê°„', 'ì „ì¼ê±°ë˜ëŸ‰', 'ì•¡ë©´ê°€', 'ìƒì¥ì¼ì',  # line 69
            'ìƒì¥ì£¼ìˆ˜', 'ìë³¸ê¸ˆ', 'ê²°ì‚°ì›”', 'ê³µëª¨ê°€', 'ìš°ì„ ì£¼',  # line 75
            'ê³µë§¤ë„ê³¼ì—´', 'ì´ìƒê¸‰ë“±', 'KRX300', 'ë§¤ì¶œì•¡', 'ì˜ì—…ì´ìµ',  # line 80
            'ê²½ìƒì´ìµ', 'ë‹¹ê¸°ìˆœì´ìµ', 'ROE', 'ê¸°ì¤€ë…„ì›”', 'ì‹œê°€ì´ì•¡',  # line 85
            'ê·¸ë£¹ì‚¬ì½”ë“œ', 'íšŒì‚¬ì‹ ìš©í•œë„ì´ˆê³¼', 'ë‹´ë³´ëŒ€ì¶œê°€ëŠ¥', 'ëŒ€ì£¼ê°€ëŠ¥'
        ]

        df2 = pd.read_fwf(tmp_fil2, widths=field_specs, names=part2_columns)
        df = pd.merge(df1, df2, how='outer', left_index=True, right_index=True)

        # clean temporary file and dataframe
        del (df1)
        del (df2)
        os.remove(tmp_fil1)
        os.remove(tmp_fil2)
        return df

    def fetch_kospi_symbols(self):
        """ì½”ìŠ¤í”¼ ì¢…ëª© ì½”ë“œ

        ì‹¤ì œ í•„ìš”í•œ ì¢…ëª©: ST, RT, EF, IF

        ST	ì£¼ê¶Œ
        MF	ì¦ê¶Œíˆ¬ìíšŒì‚¬
        RT	ë¶€ë™ì‚°íˆ¬ìíšŒì‚¬
        SC	ì„ ë°•íˆ¬ìíšŒì‚¬
        IF	ì‚¬íšŒê°„ì ‘ìë³¸íˆ¬ìœµìíšŒì‚¬
        DR	ì£¼ì‹ì˜ˆíƒì¦ì„œ
        EW	ELW
        EF	ETF
        SW	ì‹ ì£¼ì¸ìˆ˜ê¶Œì¦ê¶Œ
        SR	ì‹ ì£¼ì¸ìˆ˜ê¶Œì¦ì„œ
        BC	ìˆ˜ìµì¦ê¶Œ
        FE	í•´ì™¸ETF
        FS	ì™¸êµ­ì£¼ê¶Œ


        Returns:
            DataFrame:
        """
        base_dir = os.getcwd()
        file_name = "kospi_code.mst.zip"
        url = "https://new.real.download.dws.co.kr/common/master/" + file_name
        self.download_master_file(base_dir, file_name, url)
        df = self.parse_kospi_master(base_dir)
        return df

    def fetch_kosdaq_symbols(self):
        """ì½”ìŠ¤ë‹¥ ì¢…ëª© ì½”ë“œ

        Returns:
            DataFrame:
        """
        base_dir = os.getcwd()
        file_name = "kosdaq_code.mst.zip"
        url = "https://new.real.download.dws.co.kr/common/master/" + file_name
        self.download_master_file(base_dir, file_name, url)
        df = self.parse_kosdaq_master(base_dir)
        return df

    def fetch_price_detail_oversea_list(self, stock_market_list):
        return self.__execute_concurrent_requests(self.__fetch_price_detail_oversea, stock_market_list)

    @retry_on_rate_limit()
    def __fetch_price_detail_oversea(self, symbol: str, market: str = "KR"):
        """í•´ì™¸ì£¼ì‹ í˜„ì¬ê°€ìƒì„¸

        Args:
            symbol (str): symbol
        """
        self.rate_limiter.acquire()

        path = "/uapi/overseas-price/v1/quotations/price-detail"
        url = f"{self.base_url}/{path}"

        headers = {
            "content-type": "application/json",
            "authorization": self.access_token,
            "appKey": self.api_key,
            "appSecret": self.api_secret,
            "tr_id": "HHDFS76200200"
        }

        if market == "KR" or market == "KRX":
            # API í˜¸ì¶œí•´ì„œ ì‹¤ì œë¡œ í™•ì¸ì€ ëª»í•´ë´„, overasea ì´ë¼ì„œ ì•ˆë  ê²ƒìœ¼ë¡œ íŒë‹¨í•´ì„œ ì¡°ê±´ë¬¸ ì¶”ê°€í•¨
            raise ValueError("Market cannot be either 'KR' or 'KRX'.")

        for market_code in MARKET_TYPE_MAP[market]:
            print("market_code", market_code)
            market_type = MARKET_CODE_MAP[market_code]
            exchange_code = EXCHANGE_CODE_MAP[market_type]
            params = {
                "AUTH": "",
                "EXCD": exchange_code,
                "SYMB": symbol
            }
            resp = requests.get(url, headers=headers, params=params)
            resp_json = resp.json()
            if resp_json['rt_cd'] != API_RETURN_CODE["SUCCESS"] or resp_json['output']['rsym'] == '':
                continue

            return resp_json

    def fetch_stock_info_list(self, stock_market_list):
        return self.__execute_concurrent_requests(self.__fetch_stock_info, stock_market_list)

    @retry_on_rate_limit()
    def __fetch_stock_info(self, symbol: str, market: str = "KR"):
        self.rate_limiter.acquire()

        path = "uapi/domestic-stock/v1/quotations/search-info"
        url = f"{self.base_url}/{path}"
        headers = {
            "content-type": "application/json",
            "authorization": self.access_token,
            "appKey": self.api_key,
            "appSecret": self.api_secret,
            "tr_id": "CTPF1604R"
        }

        for market_code in MARKET_TYPE_MAP[market]:
            try:
                params = {
                    "PDNO": symbol,
                    "PRDT_TYPE_CD": market_code
                }
                resp = requests.get(url, headers=headers, params=params)
                resp_json = resp.json()

                if resp_json['rt_cd'] == API_RETURN_CODE['NO_DATA']:
                    continue
                return resp_json

            except Exception as e:
                print(e)
                if resp_json['rt_cd'] != API_RETURN_CODE['SUCCESS']:
                    continue
                raise e

    def fetch_search_stock_info_list(self, stock_market_list):
        return self.__execute_concurrent_requests(self.__fetch_search_stock_info, stock_market_list)

    @retry_on_rate_limit()
    def __fetch_search_stock_info(self, symbol: str, market: str = "KR"):
        """
        êµ­ë‚´ ì£¼ì‹ë§Œ ì œê³µí•˜ëŠ” APIì´ë‹¤
        """

        self.rate_limiter.acquire()

        path = "uapi/domestic-stock/v1/quotations/search-stock-info"
        url = f"{self.base_url}/{path}"
        headers = {
            "content-type": "application/json",
            "authorization": self.access_token,
            "appKey": self.api_key,
            "appSecret": self.api_secret,
            "tr_id": "CTPF1002R"
        }

        if market != "KR" and market != "KRX":
            raise ValueError("Market must be either 'KR' or 'KRX'.")

        for market_ in MARKET_TYPE_MAP[market]:
            try:
                params = {
                    "PDNO": symbol,
                    "PRDT_TYPE_CD": market_
                }
                resp = requests.get(url, headers=headers, params=params)
                resp_json = resp.json()

                if resp_json['rt_cd'] == API_RETURN_CODE['NO_DATA']:
                    continue
                return resp_json

            except Exception as e:
                print(e)
                if resp_json['rt_cd'] != API_RETURN_CODE['SUCCESS']:
                    continue
                raise e


# RateLimiter í´ë˜ìŠ¤ëŠ” enhanced_rate_limiter.pyë¡œ ì´ë™ë¨


if __name__ == "__main__":
    with open("../koreainvestment.key", encoding='utf-8') as key_file:
        lines = key_file.readlines()

    key = lines[0].strip()
    secret = lines[1].strip()
    acc_no = lines[2].strip()

    broker = KoreaInvestment(
        api_key=key,
        api_secret=secret,
        acc_no=acc_no,
        # exchange="ë‚˜ìŠ¤ë‹¥" # todo: exchangeëŠ” ì œê±° ì˜ˆì •
    )

    balance = broker.fetch_present_balance()
    print(balance)

    # result = broker.fetch_oversea_day_night()
    # pprint.pprint(result)

    # minute1_ohlcv = broker.fetch_today_1m_ohlcv("005930")
    # pprint.pprint(minute1_ohlcv)

    # broker = KoreaInvestment(key, secret, exchange="ë‚˜ìŠ¤ë‹¥")
    # import pprint
    # resp = broker.fetch_price("005930")
    # pprint.pprint(resp)
    #
    # b = broker.fetch_balance("63398082")
    # pprint.pprint(b)
    #
    # resp = broker.create_market_buy_order("63398082", "005930", 10)
    # pprint.pprint(resp)
    #
    # resp = broker.cancel_order("63398082", "91252", "0000117057", "00", 60000, 5, "Y")
    # print(resp)
    #
    # resp = broker.create_limit_buy_order("63398082", "TQQQ", 35, 1)
    # print(resp)



    # import pprint
    # broker = KoreaInvestment(key, secret, exchange="ë‚˜ìŠ¤ë‹¥")
    # resp_ohlcv = broker.fetch_ohlcv("TSLA", '1d', to="")
    # print(len(resp_ohlcv['output2']))
    # pprint.pprint(resp_ohlcv['output2'][0])
    # pprint.pprint(resp_ohlcv['output2'][-1])
